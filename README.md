# Anomaly Detection in Credit Card Transactions
 
## Kaggle Notebook

[Anomaly Detection in Credit Card Transactions](https://www.kaggle.com/code/sugataghosh/anomaly-detection-in-credit-card-transactions)

## Overview

**In this project, we consider [an imbalanced dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) of [credit card frauds](https://en.wikipedia.org/wiki/Credit_card_fraud) (with the target labels being *authentic* and *fraudulent*) and build an [anomaly detection](https://en.wikipedia.org/wiki/Anomaly_detection) system to identify transactions that are, in some sense, different from the usual, authentic transactions. These observations are flagged as potentially fraudulent and put to further verification.**

- We carry out necessary feature extraction and feature transformation.
- As the anomaly detection algorithm suffers from high-dimensional data, we figure out the most relevant features separating the target classes, and use only those in the modeling purpose.
- Based on the training data, we fit a [**multivariate normal distribution**](https://en.wikipedia.org/wiki/Multivariate_normal_distribution).
- Given a new transaction, if the corresponding density value of the fitted distribution is lower than a pre-specified threshold, then we flag the transaction as fraudulent.
- In this notebook, we focus more on the true positive class (the class of fraudulent transactions) than the true negative class (the class of authentic transactions). This is because a false negative (the algorithm predicts a fraudulent transaction as authentic) is far more dangerous than a false positive (the algorithm predicts an authentic transaction as fraudulent, which can always be cross-verified). For this reason, we use [**$F_2$-score**](https://en.wikipedia.org/wiki/F-score) as the [**evaluation metric**](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers).
- The choice of the threshold is optimised by iterating over a pre-specified set of values, predicting on the validation set, and evaluating the predictions by means of the $F_2$-score.
- In this work, the optimal threshold value comes out to be $0.009^9 \approx 3.87 \times 10^{-19}$.
- The corresponding $F_2$-score for predictions on the validation set is $0.834671$, which is an optimistic projection due to the threshold tuning over the validation set.
- Applying the same model on the test set, we get predictions with an $F_2$-score of $0.816492$.

## Anomaly Detection

In [**statistics**](https://en.wikipedia.org/wiki/Statistics) and [**data analysis**](https://en.wikipedia.org/wiki/Data_analysis), an [**anomaly**](https://en.wikipedia.org/wiki/Anomaly) or [**outlier**](https://en.wikipedia.org/wiki/Outlier) refers to a rare observation which deviates significantly from the majority of the data and does not conform to a well-defined notion of normal behaviour. It is possible that such observations may have been generated by a different mechanism or appear inconsistent with the remainder of the dataset. The process of identifying such observations is generally referred to as anomaly detection. In recent days, [**machine learning**](https://en.wikipedia.org/wiki/Machine_learning) is progressively being employed to automate the process of anomaly detection through [**supervised learning**](https://en.wikipedia.org/wiki/Supervised_learning) (when observations are [**labeled**](https://en.wikipedia.org/wiki/Labeled_data) as *normal* or *anomalous*), [**semi-supervised learning**](https://en.wikipedia.org/wiki/Semi-supervised_learning) (when only a small fraction of observations are labeled) and [**unsupervised learning**](https://en.wikipedia.org/wiki/Unsupervised_learning) (when observations are not labeled). Anomaly detection is particularly suitable in the following setup:

- Anomalies are very rare in the dataset
- The features of anomalous observations differ significantly from those of normal observations
- Anomalies may result for different (potentially new) reasons

Anomaly detection can be very useful in credit card fraud detection. Fraudulent transactions are rare compared to authentic transactions. Also, the methods through which fraudulent transactions occur keep evolving, as the old ways get flagged by existing fraud detection systems. In this notebook, we shall develop a basic anomaly detection system that flags transactions with feature values deviating significantly from those of authentic transactions.

## Data

**Source:** **https://www.kaggle.com/mlg-ulb/creditcardfraud**

The dataset contains information on the transactions made using credit cards by European cardholders, in two particular days of September $2013$. It presents a total of $284807$ transactions, of which $492$ were fraudulent. Clearly, the dataset is highly imbalanced, the positive class (fraudulent transactions) accounting for only $0.173\%$ of all transactions. The columns in the dataset are as follows:

- **Time:** The time (in seconds) elapsed between the transaction and the very first transaction
- **V1 to V28:** Obtained from principle component analysis (PCA) transformation on original features that are not available due to confidentiality
- **Amount:** The amount of the transaction
- **Class:** The status of the transaction with respect to authenticity. The class of an authentic (resp. fraudulent) transaction is taken to be $0$ (resp. $1$)

## Project Objective

The objective of the project is to detect anomalies in credit card transactions. To be prcise, given the data on `Time`, `Amount` and transformed features `V1` to `V28`, our goal is to fit a [**probability distribution**](https://en.wikipedia.org/wiki/Probability_distribution) based on authentic transactions, and then use it to correctly identify a new transaction as authentic or fraudulent. Note that the target variable plays no role in constructing the probability distribution.

## Evaluation Metric

Any prediction about a binary categorical target variable falls into one of the four categories:
- **True Positive:** The classification model correctly predicts the output to be positive
- **True Negative:** The classification model correctly predicts the output to be negative
- **False Positive:** The classification model incorrectly predicts the output to be positive
- **False Negative:** The classification model incorrectly predicts the output to be negative

Let **TP**, **TN**, **FP** and **FN** respectively denote the number of **true positives**, **true negatives**, **false positives** and **false negatives** among the predictions made by a particular classification model. Below we give the definitions of some evaluation metrics based on these four quantities.

\begin{align*}
&\text{Accuracy} = \frac{\text{Number of correct predictions}}{\text{Number of total predictions}} = \frac{TP + TN}{TP + TN + FP + FN}\\\\
&\text{Precision} = \frac{\text{Number of true positive predictions}}{\text{Number of total positive predictions}} = \frac{TP}{TP + FP}\\\\
&\text{Recall} = \frac{\text{Number of true positive predictions}}{\text{Number of total positive cases}} = \frac{TP}{TP + FN}\\\\
&\text{Fowlkes-Mallows index (FM)} = \text{Geometric mean of Precision and Recall} = \sqrt{\text{Precision} \times \text{Recall}}\\\\
&F_1\text{-Score} = \text{Harmonic mean of Precision and Recall} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}\\\\
&F_{\beta}\text{-score} = \frac{\left(1 + \beta^2\right) \times \text{Precision} \times \text{Recall}}{\left(\beta^2 \times \text{Precision}\right) + \text{Recall}} = \frac{\left(1 + \beta^2\right) \times TP}{\left(1 + \beta^2\right) \times TP + \beta^2 \times FN + FP},
\end{align*}

where $\beta$ is a positive factor, chosen such that Recall is $\beta$ times as important as Precision in the analysis. Popular choices of $\beta$ are $0.5$, $1$ and $2$.

\begin{align*}
&\text{Matthews Correlation Coefficient (MCC)} = \frac{\left(TP \times TN\right) - \left(FP \times FN\right)}{\sqrt{\left(TP + FP\right) \times \left(TP + FN\right) \times \left(TN + FP\right) \times \left(TN + FN\right)}}.
\end{align*}

Unlike the previous metrics, [**MCC**](https://en.wikipedia.org/wiki/Phi_coefficient) varies from $-1$ (worst case scenario) to $1$ (best case scenario: perfect prediction). Among the discussed metrics, some good choices to evaluate models, in particular for imbalanced datasets, are **MCC** and [**$F_1$-score**](https://en.wikipedia.org/wiki/F-score), while [**Precision and Recall**](https://en.wikipedia.org/wiki/Precision_and_recall) also give useful information. We shall not give much importance to the [**Accuracy**](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) metric in this project as it produces misleading conclusions when the classes are not balanced. In the problem at hand, false negative (a fraudulent transaction being classified as authentic) is more dangerous than false positive (an authentic transaction being classified as fraudulent). In the former case, the fraudster can cause further financial damage. In the latter case, the bank can cross-verify the authenticity of the transaction from the card-user after taking necessary steps to secure the card. Considering this fact, we employ $F_2$-score to tune threshold parameter and to select features in the present work. In terms of **TP**, **TN**, **FP**, and **FN**, it is given by

$$ F_2\text{-score} = \frac{5 \times TP}{5 \times TP + 4 \times FN + FP}. $$

All of the mentioned metrics are reported for both the validation set and the test set.